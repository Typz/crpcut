<doc title="crpcut - The Compartmented Robust Posix C++ Unit Tester">
<abstract>
crpcut (pronounced &quot;crap cut&quot;) is the
Compartmented Robust Posix C++ Unit Tester
<p/>
With crpcut it is easy to write tests that other unit-test frame works cannot
manage.<p/>
</abstract>
<chapter title="Introductory example">
<p/>
A complete example:<p/>
<code>
#include &lt;crpcut.hpp&gt;
#include &lt;cassert&gt;
TEST(catch_assert, NO_CORE_FILE, EXPECT_SIGNAL_DEATH(SIGABRT))
{
  int i = 3;
  assert(i==8);
}

int main(int argc, char *argv[])
{
  return crpcut::test_case_factory::run_test(argc, argv);
}
</code>
This test will fail if compiled without support for assertions, because it is
expected to die on <id>SIGABRT</id>. When it succeeds, it will catch the output
on <id>stderr</id> and add it to the test result log.
</chapter>

<chapter title="Why crpcut">
With crpcut, every test case runs in its own process and its own working
directory. If a test case fails, the process terminates immediately, before
it does further harm. This means that every test case starts from a clean
slate, unaffected by other tests. This is the compartmentalization.
<p/>
It also means that the test suite continues, even if a test crashes.
You can set deadlines for test cases, and if the allowed time is seriously
overdrawn, the test case process is killed. These two make up the robustness
part.
<p/>
You can define dependencies between test cases, so that if a fundamental
tests fails, the tests that are based on the fundamental functionality will
not even be run.
<p/>
The crpcut main process does not have any dynamic memory allocated at the
time a test case process is started, so you can run crpcut using a memory
test tool, such as <link url="http://www.valgrind.org">valgrind</link>,
 and if there is memory allocated when the test
case process terminates, you can be assured that you have found a memory leak
in your test.
<p/>
If you have a multi-core CPU, it may be beneficial to run several test cases
in parallel. crpcut allows that.
<p/>
If there are files left in the test process' working directory after the test
case process has terminated, the test case is considered failed. The working
directory is left untouched by crpcut, for you to examine.
</chapter>

<chapter title="Competition">
You may want to check out the competition and decide which system is best for
you.
<list>
<li><link url="http://code.google.com/p/googletest/">googletest</link></li>
<li><link url="http://cppunit.sourceforge.net">CppUnit</link></li>
<li><link url="http://unittest-cpp.sourceforge.net">UnitTest++</link></li>
</list>
</chapter>

<chapter title="License">
<code>
/*
 * Copyright 2009 Bjorn Fahller &lt;bjorn@fahller.se&gt;
 * All rights reserved

 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 *
 * THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 */

</code>
</chapter>

<chapter title="Requirements">
crpcut relies on a few Posix functions, and three extensions to C++ (as defined
by the 1998 standard and the 2003 corrigendum.)
<p/>
The C++ extensions are:
<definitions notion="extension" meaning="where defined">
  <def notion="variadic macros">C99/c++0x</def>
  <def notion="decltype">c++0x (typeof, which in current gcc is similar enough,
                         is tried if decltype isn&apos;t availble)</def>
  <def notion="_Exit()">C99/c++0x</def>
</definitions>
All will become standardized for C++ soon, and are since some time supported
by gcc. The lowest version tested with is 4.1.2.
<p/>
The required Posix functions are:
<definitions notion="Standard" meaning="Requirement">
  <def notion="POSIX.1"><code>EEXIST
EINTR</code></def>
  <def notion="POSIX.1-2001"><code>alloca()
chdir()
** clock_gettime(CLOCK_MONOTONIC)
** clock_gettime(CLOCK_PROCESS_CPUTIME_ID)
close()
closedir()
dup2()
++ epoll_create()
++ epoll_ctl()
++ epoll_wait()
fork()
getcwd()
gethostname()
** getitimer(ITIMER_REAL)
** getitimer(ITIMER_VIRTUAL)
kill()
mkdir()
open()
opendir()
pipe()
read()
readdir_r()
rmdir()
++ select()
** setitimer(ITIMER_REAL)
** setitimer(ITIMER_VIRTUAL)
setrlimit(RLIMIT_CORE)
setrlimit(RLIMIT_CPU)
waitid()
write()</code></def>
  <def notion="POSIX.1-2008"><code>mkdtemp()</code></def>
</definitions>
<definitions>
<def notion="**"><id>clock_gettime()</id> will be used if available.
<id>*itimer()</id> will be used as a fallback.</def>
<def notion="++"><id>epoll_*</id> will be used if available. <id>select()</id>
                 will be used as a fallback.</def>
<def notion="">On OS-X <id>mach_absolute_time()</id> and
<id>mach_timebase_info()</id> will be used for realtime measurements.</def>
</definitions>
This should work for most Linux systems. It is also likely to work for
 <link url="http://www.apple.com/macosx/">OS-X</link>, but it has not yet
been verified.
</chapter>
<chapter title="Build and Install">
  crpcut uses <link url="http://www.cmake.org">CMake</link> to manage builds and
  installs.<p/>
First obtain the crpcut sources, either a release (current is 0.3.0) from the
sourceforge
<link url="https://sourceforge.net:443/project/showfiles.php?group_id=251473">download</link>
page, or from the git repository
<id>git://crpcut.git.sourceforge.net/gitroot/crpcut</id>
<p/>
In a build directory (can be the same as the source directory)
<code>
&gt; cmake path
</code>
Where <id>path</id> is the path to the crpcut source directory.
<p/>
Should you want to use a different install directory than the
<link url="http://www.cmake.org">CMake</link> default, type instead
<code>
&gt; cmake path -DCMAKE_INSTALL_PREFIX=&lt;desired_install_directory&gt;
</code>
<p/>
If you want to enable support for
<link url="http://code.google.com/p/googlemock">google-mock</link> add also
<code>
-DWITH_GOOGLE_MOCK=yes
</code>
to the <link url="http://www.cmake.org">cmake</link> line. If
<link url="http://code.google.com/p/googlemock">google-mock</link> is not
installed in a directory that is reachable by you C++ compiler and
linker, without additional flags, provide
<link url="http://www.cmake.org">CMake</link> with the directory of
<link url="http://code.google.com/p/googlemock">google-mock</link> using:
<code>
-DGOOGLE_MOCK_DIR=path
</code>
where path is the exact same as used in the <id>--prefix=path</id> option for
<id>configure</id>.
<p/>
Once <link url="http://www.cmake.org">CMake</link> has completed, build crpcut
by typing:
<code>
&gt; make
</code>
<p/>
Once built, you may want to check that it works correctly. Do that by
running:
<code>
&gt; make selftest
</code>
It takes about 30 seconds to run through all tests. It verifies that the test
cases under <id>test-src</id> completes with the expected result for a large set
of command-line switches.
<p/>
You can now install crpcut by typing:
<code>
&gt; make install
</code>
The file <id>install_manifest.txt</id> is created and includes the full path
of all installed files.
</chapter>
<chapter title="Writing tests">
Test cases are defined using the <id>TEST()</id> macro as:<p/>
<code>
TEST(name_of_testcase (,(fixture|modifier))*)
{
  ... code
}
</code>
Both <link section="Fixtures">fixtures</link> and
<link section="Modifiers">modifiers</link>
are explained below.
<p/>
If several tests are related, they can be grouped into a test suite using the
<id>TESTSUITE()</id> macro. For a large range of tests, it may be a good idea
to nest test suites. Test cases can be written in several files and linked to
one main program. If several files define the same test-suite name, the tests
will be joined it the same suite. The <id>crpcut_</id> name prefix is reserved
for crpcut.
<p/>
In tests, assert correctness using unary and binary assertion macros.
<p/>
The unary assertions are:
<definitions notion="assert" meaning="condition">
  <def notion="ASSERT_TRUE(expr)">Fails iff <id>expr</id> evaluates to
                                 <id>false</id></def>
  <def notion="ASSERT_FALSE(expr)">Fails iff <id>expr</id> evaluates to
                                   <id>true</id></def>
  <def notion="ASSERT_NO_THROW(expr)">Fails iff <id>expr</id> throws
                                      anything</def>
</definitions>
<p/>
The binary assertions are:
<definitions notion="assert" meaning="condition">
  <def notion="ASSERT_EQ(a, b)">Fails iff the expression <id>(a == b)</id>
                                evaluates to <id>false</id></def>
  <def notion="ASSERT_NE(a, b)">Fails iff the expression <id>(a != b)</id>
                                evaluates to <id>false</id></def>
  <def notion="ASSERT_GT(a, b)">Fails iff the expression <id>(a &gt; b)</id>
                                evaluates to <id>false</id></def>
  <def notion="ASSERT_GE(a, b)">Fails iff the expression <id>(a &gt;= b)</id>
                                evaluates to <id>false</id></def>
  <def notion="ASSERT_LT(a, b)">Fails iff the expression <id>(a &lt; b)</id>
                                evaluates to <id>false</id></def>
  <def notion="ASSERT_LE(a, b)">Fails iff the expression <id>(a &lt;= b)</id>
                                evaluates to <id>false</id></def>
  <def notion="ASSERT_THROW(expr,&#xA0;exc_type)">Fails iff the expression
                                                  <id>expr</id> does not throw
                                                  an exception of type
                                                  <id>exc_type</id>. Use
                                                  <id>...</id> for
                                                  <id>exc_type</id> if any
                                                  exception is good.</def>
</definitions>
If an assertion fails, the value of the parameters is included in the failure
log (as output streamed, if possible, or as hex-dump otherwise.) All assert
macros evaluates each parameter value exactly once, so providing parameters with
side effects is not a problem. The order of evaluation of the parameters is
undefined, however.
<p/>
In addition to the assertions, two output streamers are available. Both
are used as normal <id>std::ostream</id> objects.
<definitions notion="streamer" meaning="action">
<def notion="FAIL">Immediately terminate the test case as a failure with the
                   streamed message.</def>
<def notion="INFO">Add the streamed message to the test-case log, but do
                   not fail it.</def>
</definitions>
<p/>
An example:
<code>
TEST(fail_immediately)
{
  int n = random();
  INFO &lt;&lt; "random value is " &lt;&lt; n;
  FAIL &lt;&lt; "Goodbye cruel world";
}
</code>
<section title="Fixtures">
If several test cases share the same test setup, test fixtures can be written.
A fixture is just a <id>class</id> or <id>struct</id>, with the desired
information. The default constructor is expected to fill in the desired
information, and the destructor to clean up afterwards. Several fixtures can
be combined. The fixtures are inherited by the test case.
<p/>
Small example:
<code>
TESTSUITE(string_length)
{
  class fixture1
  {
  protected:
    fixture1() : i(3) {}
    int i;
  };
  struct fixture2
  {
    std::string msg;
    fixture2() : msg("cat");
  };

  TEST(check_length, fixture1, fixture2)
  {
    ASSERT_EQ(msg.length(), i);
  }
  TEST(check_c_length, fixture1, fixture2)
  {
    ASSERT_EQ(std::strlen(msg.c_str()), i);
  }
}
</code>
</section>
<section title="Modifiers">
In addition to using fixtures and asserts, the expected behaviour of
test cases can be altered using modifiers. Modifiers are listed together with
the fixtures.
<p/>
The defined test case modifiers are:
<definitions>
<def notion="NO_CORE_FILE">Make sure the test doesn't produce a core
                           file, no matter how it crashes. Useful when
                           testing that an <id>assert()</id> works as expected.
                           </def>
<def notion="EXPECT_EXIT(code)">For the test to succeed, it must exit with the
                                supplied exit code. If any exit is OK, use
                                <id>ANY_CODE</id> for <id>code</id>.</def>
<def notion="EXPECT_SIGNAL_DEATH(code)">For the test to succeed, it must
                                        terminate on the supplied signal number.
                                        If any signal number is OK, use
                                        <id>ANY_CODE</id> for <id>code</id>.
                                        </def>
<def notion="EXPECT_EXCEPTION(type)">For the test to succeed, it must exit by
                                     throwing an instance of the provided type.
                                     If any exception is good, use
                                     <id>...</id> for
                                     <id>type</id>.</def>
<def notion="DEADLINE_CPU_MS(duration_ms)">For the test to succeed it must run
                                           to completion before consuming
                                           <id>duration_ms</id> milliseconds
                                           CPU-time. If the time consumed is
                                           vastly more, the test process will
                                           be killed (uses <id>setrlimit()</id>
                                           with <id>RLIMIT_CPU</id>, and
                                           <id>clock_gettime()</id> with
                                           <id>CLOCK_PROCESS_CPUTIME_ID</id>.)
                                           </def>
<def notion="DEADLINE_REALTIME_MS(duration_ms)">For the test to succeed it
                                                must run to completion before
                                                consuming <id>duration_ms</id>
                                                milliseconds on the
                                                rate-monotonic clock. If the
                                                time consumed is vastly more,
                                                the crpcut engine will kill it
                                                using <id>kill()</id> with
                                                signal <id>SIGKILL</id>. Time
                                                is measured using
                                                <id>clock_gettime()</id> with
                                                <id>CLOCK_MONOTONIC</id>.</def>
<def notion="DEPENDS_ON(...)">... is a list of test cases. Before the test can
                              run, all tests in the list must have finished
                              successfully.</def>
</definitions>
</section>
<section title="Disbaled tests">
If, for whatever reason, you have tests that you currently don&apos;t want to
run, but you intend for them to be included later, define them using
<id>DISABLED_TEST()</id> instead of <id>TEST()</id>. Test cases defined with
<id>DISABLED_TEST()</id> are compiled, preventing code-rot, but will never be
a candidate for running. It is not possible to state dependency on a disabled
test.
</section>
</chapter>
<chapter title="The main program">
The normal <id>main()</id> is exactly the below:
<code>
int main(int argc, char *argv[])
{
  return crpcut::test_case_factory::run_test(argc, argv);
}
</code>
<id>crpcut::test_case_factory::run_test()</id> expects parameters as a set of
flags followed by a set of test case or test suite names. The flags are:
<definitions notion="flag" meaning="meaning">
<def notion="-l">List, on stdout, all test cases matching the test case or test
                 suite names, then exit with code 0.
                 </def>
<def notion="-d&#xA0;name">Set working dir for test to named directory. The
                           directory must exist prior to run, and should
                           prefereably be empty. By default a directory is
                           created under /tmp/crpcut??????</def>
<def notion="-n">Ignore dependencies when running tests.</def>
<def notion="-v">Include the result of successful tests, in addition to that
                 of the failed ones, in the test report.</def>
<def notion="-c&#xA0;num">Control the number of parallel spawned test
                          case processes. The default is 1. If 0, the
                          test cases are run in the parent process.</def>
<def notion="-o&#xA0;file">Direct xml output to named file. Brief result
                           will be displayed on stdout.</def>
<def notion="-q">Don't display the -o brief</def>
<def notion="-x">Print XML-output on stdout or non-XML to named file
                 (-o above)</def>
</definitions>
Note that running test cases in the parent process has severe implications and
should really only be used when debugging a test case (below.) The whole test
program will terminate when reaching the first failed test. Tests that die,
will also terminate the program, even if death is expected.
<p/>
To run the tests in test suite named &quot;asserts&quot;, 8 test cases in
parallel, ignore all dependencies, and print also successful tests, start the
test program using <id>-n&#xA0;-v&#xA;-c&#xA;8 asserts</id>.
<p/>
The exact prototype for <id>run_test</id> is:
<code>
namespace crpcut {
  class test_case_factory
  {
  public:
    static int run_test(int argc, const char *argv[], std::ostream &amp; = std::cerr);
  };
}
</code>
The return value is the number of failed tests, or -1 if anything was printed
on the stream. The output stream is where to print information if the
parameters in the call don&apos;t make sense.
<p/>
The result from a test run is printed on stdout, or the file named with
the <id>-o</id> flag. By default, the result on stdout is a human readable
format, while output to a named file (the <id>-o</id> flag) is formatted using
the XML Schema provided in <id>crpcut.xsd</id>. The <id>-x</id> flag inverts
the output formats so output on stdout becomes XML-formatted and named file
output becomes human readable.
<p/>
The test program must be linked with <id>libcrpcut.so</id>. If you use
<link url="http://code.google.com/p/googlemock">google-mock</link>, you must
also link with <id>libgmock.so</id> from the
<link url="http://code.google.com/p/googlemock">google-mock</link> installation,
and <id>libcrpcut_gmock.so</id>. Do NOT link with <id>libgtest.so</id>.
</chapter>

<chapter title="Debugging">
Debugging a test case is easy. Load the test program into your favourite
debugger. Set a break point on <id>testcasename::test</id>. Run with
<id>-n&#xA0;-c&#xA0;0&#xA0;testcasename</id>. Example:
<code>
&gt; $ gdb ./testprog
GNU gdb 6.7.1
Copyright (C) 2007 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.  Type &quot;show copying&quot;
and &quot;show warranty&quot; for details.
This GDB was configured as &quot;x86_64-pc-linux-gnu&quot;...
Using host libthread_db library &quot;/lib/libthread_db.so.1&quot;.
(gdb) break asserts::should_succeed_assert_no_throw::test
Breakpoint 1 at 0x804a71c: file unitt.cpp, line 105.
(gdb) run -c 0 -n asserts::should_succeed_assert_no_throw
Starting program: ./testprog -c 0 -n asserts::should_succeed_assert_no_throw
[Thread debugging using libthread_db enabled]
[New Thread 0xf7c9a8e0 (LWP 25339)]

asserts::should_succeed_assert_no_throw[Switching to Thread 0xf7c9a8e0 (LWP 25339)]

Breakpoint 1, asserts::should_succeed_assert_no_throw::test (this=0x807a688) at unitt.cpp:105
105         ASSERT_NO_THROW(i=1);
(gdb)
</code>
From there, you can single step the test case.
</chapter>
<chapter title="Advanced techniques">
<section title="File system access">
Since all test cases run in their own working directory, the path to the
working directory when starting the test suite is lost. If you need that
path, for example to populate test vectors from a file, you can get the
path name through the static member function:
<code>
const char *crpcut::test_case_factory::get_start_dir();
</code>
</section>
<section title="Wrapping library functions">
crpcut accesses all functions it uses from <id>libc</id> and <id>librt</id>
directly from the lib by means of <id>dlsym()</id>. It does this through wrapper
functions in namespace <id>crpcut::wrapped</id>. This means that you can define
your own versions of those functions in global namespace, if you need it
for your testing. Be aware, however, that the C++ standard library may
use some of these functions, and so may
<link url="http://code.google.com/p/googlemock">google-mock</link>. So,
while creating your own
<id>int&#xA0;write(int&#xA0;fd,&#xA0;const&#xA0;void&#xA0;*addr,&#xA0;size_t&#xA0;bytes)</id>
will not harm crpcut, it will probably cause <id>std::ofstream</id> to
misbehave.
<p/>
If you need to create wrappers of your own, you can easily do that
through the macros and traits templates available in <id>crpcut.hpp</id>.
<code>
CRPCUT_WRAP_FUNC(libname, funcname, rettype, prototype_params, call_params)
</code>
<definitions notion="macro param" meaning="meaning">
<def notion="libname">name of the library in which the function resides.
                      Predefined names are <id>libc</id> and
                      <id>librt</id></def>
<def notion="funcname">The name of the function, without quotes.</def>
<def notion="rettype">The return type of the function.</def>
<def notion="prototype_params">Types and names for all parameters to the
                               function, enclosed in parenthesis.</def>
<def notion="call_params">The names from <id>prototype_params</id> without
                          type information, comma separated and enclosed in
                          parenthesis.</def>
</definitions>
For functions without return value, there's also a <id>CRPCUT_WRAP_V_FUNC()</id>
macro. It has the exact same parameter list (including <id>rettype</id>, which
typically is <id>void</id>, but may optionally include some attribute, like
<id>__attribute__((noreturn))</id>.)
<p/>
This is easiest to explain through an example. Say you want to intercept
all calls to <id>fopen()</id>. You want it to do what it normally does,
but you want to validate its parameters. A way of doing that is as follows:
<code>
extern "C" {
  #include &lt;stdio.h&gt;
}
#include &lt;crpcut.hpp&gt;

CRPCUT_WRAP_FUNC(libc, fopen, FILE*, (const char *p, const char *m), (p, m))

FILE* fopen(const char *p, const char *m)
{
  ASSERT_TRUE(p);
  ASSERT_TRUE(m);
  return crpcut::fopen(p, m);
}
</code>
By default the libraries <id>libc</id> and <id>librt</id> are known by
crpcut. If you want to access functions in other libraries, you add your
own constants under the namespace <id>crpcut::libs</id>. These must be
positive integers. You also provide your own specialization of the
traits template
<id>const&#xA0;char&#xA0;*crpcut::libwrapper::traits&lt;int&gt;::name</id>.
A complete example for the function <id>asin()</id> in the <id>libm</id>
library:
<code>
extern "C" {
  #include &lt;math.h&gt;
}
#include &lt;crpcut.hpp&gt;

namespace crpcut {
  namespace libs {
    static const int libm = 1;
  }
  namespace libwrapper {
    template &lt;&gt;
    const char *traits&lt;libs::libm&gt;::name = "libm.so";
  }
}
CRPCUT_WRAP_FUNC(libm, asin, double, (double d), (d))
</code>
Now the function <id>crpcut::wrapped::asin()</id> will call the original
function in <id>libm</id>, and you can define your own <id>asin()</id> in
global namespace for testing purposes.
<code>
extern "C"
{
  double asin(double d)
  {
    ASSERT_GE(d, -1.0);
    ASSERT_LE(d, 1.0);
    return crpcut::wrapped::asin(d);
  }
}
</code>
</section>
</chapter>

<chapter title="Further development">
The todo list, without any regard to importance or desired implementation
order is:
<list>
<li>Set regexp match rules for stdout and stderr</li>
<li>ASSERT_*() macros for almost-equal tests of floating point numbers</li>
<li>Better separation of fixture errors and test-case errors</li>
<li>Handle <id>wchar_t</id> -&gt; UTF-8 conversion for google-mock</li>
</list>
</chapter>
<chapter title="Contact">
Discussions on how to use crpcut is best managed on the crpcut-users
mailinglist. Visit the
<link url="http://lists.sourceforge.net/mailman/listinfo/crpcut-users">source-forge</link>
page for subscription.
<p/>
For bug reports, visit the
<link url="http://sourceforge.net/tracker/?group_id=251473&amp;atid=1126597">bug-tracker</link>
page on sourceforge. Make sure you really have a new bug before reporting.
</chapter>
</doc>

